# Configuración principal del proyecto RAG Benchmark

# Configuración de LLM
llm:
  provider: "openai"  # openai, anthropic, local
  model: "gpt-3.5-turbo"
  temperature: 0.1
  max_tokens: 1000

# Configuración de embeddings
embeddings:
  model: "text-embedding-ada-002"  # Para OpenAI
  # model: "sentence-transformers/all-MiniLM-L6-v2"  # Para local
  dimension: 1536
  batch_size: 100

# Configuración de bases de datos vectoriales
vector_stores:
  chroma:
    persist_directory: "./Data/embeddings/chroma"
    collection_name: "rag_documents"
  
  faiss:
    index_path: "./Data/embeddings/faiss_index"
  
  pinecone:
    api_key: "${PINECONE_API_KEY}"
    environment: "us-west1-gcp"
    index_name: "rag-benchmark"

# Configuración específica para Graph RAG
graph_rag:
  neo4j:
    uri: "bolt://localhost:7687"
    username: "neo4j"
    password: "${NEO4J_PASSWORD}"
  
  entity_extraction:
    model: "gpt-3.5-turbo"
    max_entities_per_chunk: 10
  
  relationship_extraction:
    model: "gpt-3.5-turbo"
    max_relationships_per_chunk: 5

# Configuración para Rewrite RAG
rewrite_rag:
  query_rewrite:
    model: "gpt-3.5-turbo"
    num_rewrites: 3
    temperature: 0.3
  
  retrieval:
    top_k: 10
    rerank: true

# Configuración para Hybrid RAG
hybrid_rag:
  weights:
    graph_score: 0.4
    vector_score: 0.6
  
  fusion_method: "weighted"  # weighted, rrf, linear_combination

# Configuración de evaluación
evaluation:
  metrics:
    - "bleu"
    - "rouge"
    - "bert_score"
    - "faithfulness"
    - "relevance"
  
  test_sets:
    - "qa_pairs"
    - "multi_hop_questions"
    - "factual_questions"

# Configuración de datos
data:
  chunk_size: 1000
  chunk_overlap: 200
  supported_formats: [".txt", ".pdf", ".docx", ".md"]

# Configuración de logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/rag_benchmark.log"