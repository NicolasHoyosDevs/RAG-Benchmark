"""
Script de prueba para la funciÃ³n query_for_evaluation
"""

import sys
from pathlib import Path

# Agregar el directorio del proyecto al path para importar
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# Importar la funciÃ³n de evaluaciÃ³n
from Query_Rewriter_RAG.main_rewriter import query_for_evaluation

def test_evaluation_function():
    """Prueba la funciÃ³n de evaluaciÃ³n con una pregunta de ejemplo"""
    
    print("ğŸ§ª === PRUEBA DE FUNCIÃ“N DE EVALUACIÃ“N ===")
    print("Probando query_for_evaluation con una pregunta de embarazo...")
    
    # Pregunta de prueba
    test_question = "Â¿QuÃ© es la preeclampsia y cuÃ¡les son sus sÃ­ntomas?"
    
    try:
        # Llamar a la funciÃ³n de evaluaciÃ³n
        result = query_for_evaluation(test_question)
        
        # Verificar estructura del resultado
        print("\nâœ… FunciÃ³n ejecutada exitosamente!")
        print(f"ğŸ“‹ Estructura del resultado:")
        print(f"   - question: {type(result.get('question'))} ({'âœ“' if result.get('question') else 'âœ—'})")
        print(f"   - answer: {type(result.get('answer'))} ({'âœ“' if result.get('answer') else 'âœ—'})")
        print(f"   - contexts: {type(result.get('contexts'))} con {len(result.get('contexts', []))} elementos")
        print(f"   - source_documents: {type(result.get('source_documents'))} con {len(result.get('source_documents', []))} elementos")
        print(f"   - metadata: {type(result.get('metadata'))} ({'âœ“' if result.get('metadata') else 'âœ—'})")
        
        # Mostrar contenido de ejemplo
        print(f"\nğŸ“„ Contenido de ejemplo:")
        print(f"   Pregunta: {result['question']}")
        print(f"   Respuesta (primeros 200 chars): {result['answer'][:200]}...")
        print(f"   NÃºmero de contextos: {len(result['contexts'])}")
        print(f"   Metadatos: {result['metadata']}")
        
        # Verificar que contexts es una lista de strings
        if result.get('contexts'):
            print(f"   Primer contexto (primeros 100 chars): {result['contexts'][0][:100]}...")
        
        print("\nğŸ‰ Â¡FunciÃ³n lista para usar con RAGAS!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Error al ejecutar la funciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_evaluation_function()
    if success:
        print("\nâœ… Prueba completada exitosamente")
    else:
        print("\nâŒ Prueba fallÃ³")