# RAG Benchmark - ComparaciÃ³n de Implementaciones RAG

Este proyecto implementa y evalÃºa tres tipos diferentes de sistemas RAG (Retrieval-Augmented Generation):

## ğŸ¯ Tipos de RAG Implementados

### 1. **Graph RAG**
- Extrae entidades y relaciones de los documentos
- Construye un grafo de conocimiento
- Responde consultas navegando el grafo
- Ideal para preguntas que requieren mÃºltiples saltos de razonamiento

### 2. **Rewrite RAG**
- Reescribe consultas de mÃºltiples formas
- Mejora la recuperaciÃ³n con diferentes versiones de la pregunta
- Fusiona resultados de mÃºltiples bÃºsquedas
- Ideal para consultas ambiguas o complejas

### 3. **Hybrid RAG**
- Combina Graph RAG y Rewrite RAG
- Fusiona resultados usando diferentes estrategias
- Aprovecha las fortalezas de ambos enfoques
- Ideal para casos de uso diversos

## ğŸ—ï¸ Estructura del Proyecto

```
RAG-Benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rags/                    # Implementaciones RAG
â”‚   â”‚   â”œâ”€â”€ graph_rag/          # Graph RAG
â”‚   â”‚   â”œâ”€â”€ rewrite_rag/        # Rewrite RAG
â”‚   â”‚   â””â”€â”€ hybrid_rag/         # Hybrid RAG
â”‚   â”œâ”€â”€ common/                  # Utilidades compartidas
â”‚   â”œâ”€â”€ evaluation/              # Sistema de evaluaciÃ³n
â”‚   â””â”€â”€ utils/                   # Utilidades generales
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ raw/                     # Documentos originales
â”‚   â”œâ”€â”€ processed/               # Documentos procesados
â”‚   â”œâ”€â”€ embeddings/              # Embeddings vectoriales
â”‚   â”œâ”€â”€ graphs/                  # Datos de grafos
â”‚   â””â”€â”€ queries/                 # Consultas de prueba
â”œâ”€â”€ config/                      # Configuraciones
â”œâ”€â”€ tests/                       # Tests unitarios
â”œâ”€â”€ scripts/                     # Scripts de ejecuciÃ³n
â”œâ”€â”€ docs/                        # DocumentaciÃ³n
â””â”€â”€ results/                     # Resultados de evaluaciÃ³n
```

## ğŸš€ ConfiguraciÃ³n Inicial

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2. Configurar Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tus API keys
```

### 3. Configurar Neo4j (para Graph RAG)

```bash
# Docker
docker run -p7474:7474 -p7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest

# O instalar localmente
# https://neo4j.com/download/
```

## ğŸ§ª Ejecutar Benchmark

### EjecuciÃ³n Completa

```bash
cd scripts
python run_benchmark.py
```

### EjecuciÃ³n Individual

```python
import asyncio
from src.rags.graph_rag import GraphRAG

async def test_graph_rag():
    config = {...}  # Tu configuraciÃ³n
    rag = GraphRAG(config)
    await rag.initialize()
    
    # AÃ±adir documentos
    await rag.add_documents(["Documento de ejemplo..."])
    
    # Hacer consulta
    response = await rag.query("Â¿QuÃ© dice el documento?")
    print(response.answer)

asyncio.run(test_graph_rag())
```

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El sistema evalÃºa automÃ¡ticamente:

- **BLEU Score**: PrecisiÃ³n de n-gramas
- **ROUGE Scores**: Recall de n-gramas y secuencias
- **BERT Score**: Similaridad semÃ¡ntica
- **Faithfulness**: Fidelidad al contexto
- **Relevance**: Relevancia de la respuesta
- **Tiempo de Respuesta**: Performance

## âš™ï¸ ConfiguraciÃ³n

Edita `config/config.yaml` para personalizar:

```yaml
# ConfiguraciÃ³n de LLM
llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  temperature: 0.1

# ConfiguraciÃ³n especÃ­fica para Graph RAG
graph_rag:
  entity_extraction:
    model: "gpt-3.5-turbo"
    max_entities_per_chunk: 10

# ConfiguraciÃ³n para Rewrite RAG
rewrite_rag:
  query_rewrite:
    num_rewrites: 3
    temperature: 0.3

# ConfiguraciÃ³n para Hybrid RAG
hybrid_rag:
  weights:
    graph_score: 0.4
    vector_score: 0.6
  fusion_method: "weighted"
```

## ğŸ§° Uso ProgramÃ¡tico

### Ejemplo BÃ¡sico

```python
from src.rags import GraphRAG, RewriteRAG, HybridRAG
import asyncio

async def main():
    # ConfiguraciÃ³n
    config = load_config("config/config.yaml")
    
    # Inicializar RAG
    rag = HybridRAG(config)
    await rag.initialize()
    
    # AÃ±adir documentos
    documents = ["Tu contenido aquÃ­..."]
    await rag.add_documents(documents)
    
    # Hacer consulta
    response = await rag.query("Â¿CuÃ¡l es la respuesta?")
    
    print(f"Respuesta: {response.answer}")
    print(f"Confianza: {response.confidence}")
    print(f"Fuentes: {len(response.sources)}")

asyncio.run(main())
```

### EvaluaciÃ³n Personalizada

```python
from src.evaluation import RAGEvaluator, RAGMetrics

# Configurar evaluador
metrics = RAGMetrics()
evaluator = RAGEvaluator(metrics)

# Evaluar consulta individual
result = await evaluator.evaluate_single(
    rag_system=rag,
    question="Â¿QuÃ© es la IA?",
    ground_truth="La IA es...",
    context="Contexto relevante..."
)
```

## ğŸ“ˆ Resultados

Los resultados se guardan en `results/` con:

- MÃ©tricas individuales por consulta
- Promedios por sistema RAG
- ComparaciÃ³n entre sistemas
- Mejores performers por mÃ©trica

## ğŸ”§ Extensibilidad

### AÃ±adir Nueva MÃ©trica

```python
from src.evaluation.metrics import RAGMetrics

class CustomMetrics(RAGMetrics):
    async def calculate_custom_metric(self, prediction, reference):
        # Tu lÃ³gica aquÃ­
        return {"custom_score": score}
```

### Crear Nuevo Tipo de RAG

```python
from src.common.base_rag import BaseRAG, RAGResponse

class MyCustomRAG(BaseRAG):
    async def initialize(self):
        # Tu inicializaciÃ³n
        pass
    
    async def query(self, question):
        # Tu lÃ³gica de consulta
        return RAGResponse(answer="...", sources=[], confidence=0.8)
```

## ğŸ“š DocumentaciÃ³n Adicional

- [GuÃ­a de Graph RAG](docs/graph_rag.md)
- [GuÃ­a de Rewrite RAG](docs/rewrite_rag.md)
- [GuÃ­a de Hybrid RAG](docs/hybrid_rag.md)
- [API Reference](docs/api_reference.md)

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature
3. AÃ±ade tests para nuevas funcionalidades
4. EnvÃ­a un pull request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ†˜ Soporte

- Issues: GitHub Issues
- DocumentaciÃ³n: `/docs`
- Email: [tu-email@ejemplo.com]